{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMGNETPROTOTYPE.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "fmEl2D_AjHnZ"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOZz+kL4Bwgfoy0Sr35hs2d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyang0129/project/blob/main/IMGNETPROTOTYPE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IVSuOCWNxf_"
      },
      "source": [
        "# SETUP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utmp5Q2XjTb6"
      },
      "source": [
        "!pip install -q einops"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chyHh79ioXxu"
      },
      "source": [
        "import math, re, os\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow.keras.layers as L\r\n",
        "from sklearn import metrics\r\n",
        "from sklearn.model_selection import train_test_split, KFold\r\n",
        "import cv2\r\n",
        "import tensorflow_addons as tfa\r\n",
        "import PIL\r\n",
        "import tensorflow.keras.backend as K\r\n",
        "from tqdm.notebook import tqdm\r\n",
        "import tensorflow_datasets as tfds\r\n",
        "from einops import rearrange\r\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhbIu6NQfS-q",
        "outputId": "c397ac7e-2dba-4dc5-d292-c4e9b11d9088"
      },
      "source": [
        "import os\r\n",
        "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\r\n",
        "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\r\n",
        "print('TPU address is', TPU_ADDRESS)\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "# Detect hardware, return appropriate distribution strategy\r\n",
        "try:\r\n",
        "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\r\n",
        "    # set: this is always the case on Kaggle.\r\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\r\n",
        "    print('Running on TPU ', tpu.master())\r\n",
        "except ValueError:\r\n",
        "    tpu = None\r\n",
        "\r\n",
        "if tpu:\r\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\r\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\r\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\r\n",
        "else:\r\n",
        "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\r\n",
        "    strategy = tf.distribute.get_strategy()\r\n",
        "\r\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU address is grpc://10.38.226.50:8470\n",
            "Running on TPU  grpc://10.38.226.50:8470\n",
            "INFO:tensorflow:Initializing the TPU system: grpc://10.38.226.50:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.38.226.50:8470\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tth5AIjVNzjd"
      },
      "source": [
        "# HYPER PARAMETERS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAcRKNX9N0ni"
      },
      "source": [
        "class P():\r\n",
        "    epochs = 100 \r\n",
        "    net_input_dim = (224, 224, 3) \r\n",
        "    batch_size = 256\r\n",
        "    num_train_img = 1281167\r\n",
        "    shuffle_buffer_size = 4096\r\n",
        "    mean = [103.939, 116.779, 123.68]\r\n",
        "    std = [58.393, 57.12, 57.375]\r\n",
        "    num_class = 1000\r\n",
        "    initial_learning_rate = 0.05\r\n",
        "    minimum_learning_rate = 0.0001\r\n",
        "    epoch_num = epochs \r\n",
        "    iterations_per_epoch = num_train_img / batch_size\r\n",
        "    steps_per_epoch = iterations_per_epoch\r\n",
        "    warm_iterations = iterations_per_epoch\r\n",
        "    architecture = 'resnet' # resnet, botnet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-va4z2q1PJ_Y"
      },
      "source": [
        "# DATASET DEFINITION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1SL8xbKPMq3"
      },
      "source": [
        "## AUGMENTATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkK-qxQ1POeJ"
      },
      "source": [
        "def augment_image(example):\r\n",
        "\r\n",
        "    image = example['image']\r\n",
        "\r\n",
        "\r\n",
        "    image = tf.image.resize_with_pad(image, 256,256)\r\n",
        "    # IMPLEMENT ZOOM \r\n",
        "    # image = random_size(image)\r\n",
        "    image = tf.image.random_crop(image, P.net_input_dim)\r\n",
        "    image = tf.image.random_flip_left_right(tf.image.random_flip_up_down(image))\r\n",
        "\r\n",
        "    example['image'] = image \r\n",
        "\r\n",
        "    return example\r\n",
        "\r\n",
        "def process_image(example):\r\n",
        "\r\n",
        "    image = example['image']\r\n",
        "    image = tf.image.resize_with_pad(image, 256,256)\r\n",
        "    image = tf.image.central_crop(image, 0.875)\r\n",
        "    image = tf.image.resize_with_pad(image, P.net_input_dim[0], P.net_input_dim[1])\r\n",
        "\r\n",
        "    example['image'] = image \r\n",
        "\r\n",
        "    return example \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def normalize(example): \r\n",
        "    image = example['image']\r\n",
        "    image = tf.cast(image, tf.float32)\r\n",
        "\r\n",
        "    image = image - P.mean \r\n",
        "    iamge = image / P.std\r\n",
        "\r\n",
        "    image = image/255.\r\n",
        "    example['image'] = image \r\n",
        "    return example \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5y1rTa0PPa3"
      },
      "source": [
        "## DATASET PREPARATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0JYFKWFPR9-"
      },
      "source": [
        "\r\n",
        "def get_dataset(ds, augment = False, shuffle = P.shuffle_buffer_size, batch = P.batch_size, repeat = False): \r\n",
        "\r\n",
        "    ds = ds.repeat() if repeat else ds \r\n",
        "    ds = ds.map(normalize)\r\n",
        "    ds = ds.map(augment_image) if augment else ds.map(process_image)\r\n",
        "    ds = ds.shuffle(shuffle) if shuffle else ds \r\n",
        "    ds = ds.batch(batch) if batch else ds \r\n",
        "\r\n",
        "    return ds \r\n",
        "\r\n",
        "\r\n",
        "    \r\n",
        "ds_train, ds_valid = tfds.load(name=\"imagenet2012\", \r\n",
        "                              split=[\"train\", \"validation\"], \r\n",
        "                              data_dir=\"gs://kaggledata2/imgnet\", \r\n",
        "                              builder_kwargs={\"version\": \"5.0.0\"},)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVYmrUWpPVG_"
      },
      "source": [
        "## DATA SAMPLES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X26jQJNjPL7_"
      },
      "source": [
        "plt.rcParams['figure.figsize'] = [12, 8]\r\n",
        "plt.rcParams['figure.dpi'] = 100\r\n",
        "\r\n",
        "ds  = get_dataset(ds_train, augment = True , shuffle = False, repeat = True)\r\n",
        "\r\n",
        "\r\n",
        "def draw_grid(imgs, nrow, ncol):\r\n",
        "\r\n",
        "    fig, axs = plt.subplots(nrows=nrow, ncols=ncol)\r\n",
        "\r\n",
        "    for i, ax in enumerate(axs.reshape(-1)):\r\n",
        "\r\n",
        "        img = imgs[i].numpy()\r\n",
        "        \r\n",
        "        ax.imshow(img)\r\n",
        "        \r\n",
        "\r\n",
        "draw_grid(list(ds.take(1))[0]['image'][:8], 2, 4)\r\n",
        "\r\n",
        "\r\n",
        "# list(ds.take(1))[0][1][:8]\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yK-xu8sai8aU"
      },
      "source": [
        "# MODEL DEFINITION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8S07p_qhi-4a"
      },
      "source": [
        "## BASIC RESNET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc0d_PPyi-Fw"
      },
      "source": [
        "\r\n",
        "\r\n",
        "def build_resnet():\r\n",
        "\r\n",
        "    model = tf.keras.applications.ResNet50(weights = None, input_shape=P.net_input_dim)\r\n",
        "\r\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmEl2D_AjHnZ"
      },
      "source": [
        "## BOTTLE TRANSFORMER COMMON"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWSiBkyujNQA"
      },
      "source": [
        "def rel_to_abs(x, b, heads_by_width, l):\r\n",
        "    h = heads_by_width\r\n",
        "    dtype = tf.keras.mixed_precision.experimental.global_policy().compute_dtype\r\n",
        "\r\n",
        "    x = tf.pad(x, paddings = [[0,0], [0,0], [0,0], [0,1]])\r\n",
        "    \r\n",
        "    flat_x = rearrange(x, 'b h l c -> b h (l c)')\r\n",
        "\r\n",
        "    flat_x_padded = tf.pad(flat_x, paddings = [[0,0], [0,0], [0,l-1]])\r\n",
        "\r\n",
        "    final_x = tf.reshape(flat_x_padded, (-1, h, l+1, 2*l - 1))\r\n",
        "    final_x = final_x[:, :, :l, (l-1):]\r\n",
        "\r\n",
        "    return final_x \r\n",
        "\r\n",
        "def expand_dim(t, dim, k):\r\n",
        "    t = tf.expand_dims(t, axis = dim)\r\n",
        "    t = tf.repeat(t, k, axis = dim)\r\n",
        "    return t \r\n",
        "\r\n",
        "\r\n",
        "def relative_logits_1d(q, rel_k, b, heads, h, w, dim):\r\n",
        "    logits = tf.einsum('b h x y d, r d -> b h x y r', q, rel_k)\r\n",
        "    logits = rearrange(logits, 'b h x y r -> b (h x) y r')\r\n",
        "\r\n",
        "    logits = rel_to_abs(logits, b, heads * w, w)\r\n",
        "    logits = tf.reshape(logits, (-1, heads, h, w, w))\r\n",
        "    logits = expand_dim(logits, dim = 3, k = h)\r\n",
        "    \r\n",
        "    return logits\r\n",
        "\r\n",
        "\r\n",
        "class RelPosEmb(tf.keras.layers.Layer):\r\n",
        "    def __init__(self, dimensions_per_head, real_input_shape, *args, **kwargs): \r\n",
        "        super().__init__(*args, **kwargs)\r\n",
        "        self.dimensions_per_head = dimensions_per_head\r\n",
        "        self.real_input_shape = real_input_shape\r\n",
        "\r\n",
        " \r\n",
        "    def build(self, input_shape): \r\n",
        "\r\n",
        "        b, h, w, c = self.real_input_shape\r\n",
        "        self.heads = input_shape[1]\r\n",
        "        self.scale = self.dimensions_per_head ** -0.5\r\n",
        "\r\n",
        "        self.height = tf.Variable(initial_value=tf.random_normal_initializer()(shape = (h * 2 - 1, self.dimensions_per_head)), dtype='float32', name= 'height')\r\n",
        "        self.width = tf.Variable(initial_value=tf.random_normal_initializer()(shape = (w * 2 - 1, self.dimensions_per_head)), dtype='float32', name='width')   \r\n",
        "\r\n",
        "    def call(self, q): \r\n",
        "        b, h, w, c = self.real_input_shape\r\n",
        "\r\n",
        "        q = rearrange(q, 'b h (x y) d -> b h x y d', x = h, y = w)\r\n",
        "        rel_logits_w = relative_logits_1d(q, self.width, b, self.heads, h, w, self.dimensions_per_head)\r\n",
        "        rel_logits_w = rearrange(rel_logits_w, 'b h x i y j-> b h (x y) (i j)')\r\n",
        "\r\n",
        "        q = rearrange(q, 'b h x y d -> b h y x d')\r\n",
        "        rel_logits_h = relative_logits_1d(q, self.height, b, self.heads, h, w, self.dimensions_per_head)\r\n",
        "        rel_logits_h = rearrange(rel_logits_h, 'b h x i y j -> b h (y x) (j i)')\r\n",
        "        return rel_logits_w + rel_logits_h\r\n",
        "\r\n",
        "    def get_config(self): \r\n",
        "        config = super().get_config()\r\n",
        "        config['dimensions_per_head'] = self.dimensions_per_head\r\n",
        "        config['real_input_shape'] = self.real_input_shape\r\n",
        "        return config \r\n",
        "\r\n",
        "class AbsEmb(tf.keras.layers.Layer): \r\n",
        "\r\n",
        "    def __init__(self, dimensions_per_head, real_input_shape, *args, **kwargs): \r\n",
        "        super().__init__(*args, **kwargs)\r\n",
        "        self.dimensions_per_head = dimensions_per_head\r\n",
        "        self.real_input_shape = real_input_shape\r\n",
        "\r\n",
        "    def build(self, input_shape): \r\n",
        "\r\n",
        "        b, h, w, c = self.real_input_shape\r\n",
        "\r\n",
        "        self.scale = self.dimensions_per_head ** -0.5\r\n",
        "\r\n",
        "        self.height = tf.Variable(initial_value=tf.random_normal_initializer()(shape = (h, self.dimensions_per_head)), dtype='float32', name= 'height')\r\n",
        "        self.width = tf.Variable(initial_value=tf.random_normal_initializer()(shape = (w, self.dimensions_per_head)), dtype='float32', name='width')\r\n",
        "\r\n",
        "    def call(self, q): \r\n",
        "        emb = rearrange(self.height, 'h d -> h () d') + rearrange(self.width, 'w d -> () w d')\r\n",
        "        emb = rearrange(emb, ' h w d -> (h w) d')\r\n",
        "        emb = tf.cast(emb, tf.keras.mixed_precision.experimental.global_policy().compute_dtype)\r\n",
        "\r\n",
        "        logits = tf.einsum('b h i d, j d -> b h i j', q, emb)\r\n",
        "        return logits \r\n",
        "\r\n",
        "    def get_config(self): \r\n",
        "        config = super().get_config()\r\n",
        "        config['dimensions_per_head'] = self.dimensions_per_head\r\n",
        "        config['real_input_shape'] = self.real_input_shape\r\n",
        "        return config \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "class Attention(tf.keras.layers.Layer): \r\n",
        "\r\n",
        "    def __init__(self, dimensions_per_head = 128, heads = 4, rel_pos_emb = False, *args, **kwargs): \r\n",
        "\r\n",
        "        super().__init__(*args, **kwargs)\r\n",
        "        self.dimensions_per_head = dimensions_per_head\r\n",
        "        self.heads = 4 \r\n",
        "        self.scale = dimensions_per_head ** -0.5\r\n",
        "        self.pos_emb_method = RelPosEmb if rel_pos_emb else AbsEmb\r\n",
        "        self.rel_pos_emb = rel_pos_emb\r\n",
        "\r\n",
        "    def build(self, input_shape): \r\n",
        "\r\n",
        "        b, h, w, c = input_shape \r\n",
        "\r\n",
        "        self.to_qkv = tf.keras.layers.Conv2D(filters = self.dimensions_per_head * self.heads * 3,\r\n",
        "                                             kernel_size = 1,\r\n",
        "                                             use_bias=False)\r\n",
        "\r\n",
        "        self.pos_emb = self.pos_emb_method(self.dimensions_per_head, input_shape)\r\n",
        "\r\n",
        "        self.h = h\r\n",
        "        self.w = w\r\n",
        "\r\n",
        "    def call(self, x): \r\n",
        "\r\n",
        "        qkv = self.to_qkv(x)\r\n",
        "        qkv = rearrange(qkv, 'b h w c -> b c h w')\r\n",
        "\r\n",
        "        q, k, v = tf.split(qkv, 3, axis = 1)\r\n",
        "        q, k, v = map(lambda t: rearrange(t, 'b (h d) x y -> b h (x y) d', h = self.heads), (q, k, v))\r\n",
        "        \r\n",
        "        q *= self.scale\r\n",
        "\r\n",
        "        sim = tf.einsum('b h i d, b h j d -> b h i j', q, k)\r\n",
        "        sim += self.pos_emb(q)\r\n",
        "\r\n",
        "        attn = tf.nn.softmax(sim, axis=-1)\r\n",
        "\r\n",
        "        out = tf.einsum('b h i j, b h j d -> b h i d', attn, v)\r\n",
        "        out = rearrange(out, 'b h (x y) d -> b (h d) x y', x = self.h, y = self.w)\r\n",
        "        out = rearrange(out, 'b c h w -> b h w c')\r\n",
        "        return out \r\n",
        "\r\n",
        "    def get_config(self): \r\n",
        "        config = super().get_config()\r\n",
        "        config['dimensions_per_head'] = self.dimensions_per_head\r\n",
        "        config['heads'] = self.heads\r\n",
        "        config['rel_pos_emb'] = self.rel_pos_emb\r\n",
        "        return config \r\n",
        "\r\n",
        "\r\n",
        "class BottleBlock(tf.keras.layers.Layer): \r\n",
        "\r\n",
        "    def __init__(self, \r\n",
        "                 output_channels, \r\n",
        "                 dimensions_per_head = 128, \r\n",
        "                 heads = 4, \r\n",
        "                 projection_factor = 4,\r\n",
        "                 downsample = False,\r\n",
        "                 pool_downsample = False, \r\n",
        "                 activation = 'relu',\r\n",
        "                 rel_pos_emb = False, \r\n",
        "                 *args, \r\n",
        "                 **kwargs): \r\n",
        "\r\n",
        "        super().__init__(*args, **kwargs)\r\n",
        "        self.dimensions_per_head = dimensions_per_head\r\n",
        "        self.heads = 4 \r\n",
        "        self.scale = dimensions_per_head ** -0.5\r\n",
        "        self.projection_factor = projection_factor\r\n",
        "        self.activation = activation \r\n",
        "        self.output_channels = output_channels\r\n",
        "        self.downsample = downsample\r\n",
        "        self.pool_downsample = pool_downsample \r\n",
        "        self.rel_pos_emb = rel_pos_emb\r\n",
        "\r\n",
        "    def build(self, input_shape): \r\n",
        "        b, h, w, c = input_shape \r\n",
        "        \r\n",
        "        att_c_in = self.output_channels//self.projection_factor\r\n",
        "        \r\n",
        "        self.net = tf.keras.Sequential([tf.keras.layers.Conv2D(att_c_in, 1),\r\n",
        "                                        tf.keras.layers.BatchNormalization(),\r\n",
        "                                        tf.keras.layers.Activation(self.activation),\r\n",
        "                                        Attention(\r\n",
        "                                            self.dimensions_per_head,\r\n",
        "                                            self.heads,\r\n",
        "                                            self.rel_pos_emb\r\n",
        "                                        ),\r\n",
        "                                        tf.keras.layers.AveragePooling2D(pool_size=(2,2)) if self.downsample else L.Activation(tf.identity),\r\n",
        "                                        tf.keras.layers.BatchNormalization(),\r\n",
        "                                        tf.keras.layers.Activation(self.activation),\r\n",
        "                                        tf.keras.layers.Conv2D(self.output_channels, 1),\r\n",
        "                                        tf.keras.layers.BatchNormalization(),\r\n",
        "                                        ])\r\n",
        "        \r\n",
        "        if c != self.output_channels or self.downsample:\r\n",
        "            if not self.pool_downsample:\r\n",
        "                    \r\n",
        "                kernel_size, stride = (3, 2) if self.downsample else (1, 1)\r\n",
        "\r\n",
        "                self.shortcut = tf.keras.Sequential([tf.keras.layers.Conv2D(self.output_channels, \r\n",
        "                                                                            kernel_size, \r\n",
        "                                                                            strides = stride,\r\n",
        "                                                                            padding = 'same'),\r\n",
        "                                                    tf.keras.layers.BatchNormalization(),\r\n",
        "                                                    tf.keras.layers.Activation(self.activation)])\r\n",
        "            else: \r\n",
        "                self.shortcut = tf.keras.Sequential([tf.keras.layers.AveragePooling2D((2,2)),\r\n",
        "                                                     tf.keras.layers.Conv2D(self.output_channels, \r\n",
        "                                                            kernel_size = 1, \r\n",
        "                                                            padding = 'same'),\r\n",
        "                                                    tf.keras.layers.BatchNormalization(),\r\n",
        "                                                    tf.keras.layers.Activation(self.activation)])\r\n",
        "            \r\n",
        "\r\n",
        "        else:\r\n",
        "            self.shortcut = L.Activation(tf.identity)\r\n",
        "\r\n",
        "    def call(self, x):\r\n",
        "        shortcut = self.shortcut(x)\r\n",
        "        x = self.net(x)\r\n",
        "        x += shortcut \r\n",
        "        return L.Activation(self.activation)(x)\r\n",
        "\r\n",
        "    def get_config(self): \r\n",
        "        config = super().get_config()\r\n",
        "        config['dimensions_per_head'] = self.dimensions_per_head\r\n",
        "        config['heads'] = self.heads\r\n",
        "        config['projection_factor'] = self.projection_factor\r\n",
        "        config['activation'] = self.activation\r\n",
        "        config['output_channels'] = self.output_channels\r\n",
        "        config['downsample'] = self.downsample\r\n",
        "        config['pool_downsample'] = self.pool_downsample\r\n",
        "        config['rel_pos_emb'] = self.rel_pos_emb\r\n",
        "        return config \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQwM0CYdjX21"
      },
      "source": [
        "## BOTTLE TRANSFORMER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhXsAt3ejZeQ"
      },
      "source": [
        "def build_bot_trans():\r\n",
        "    resnet = tf.keras.applications.ResNet50(weights = None, \r\n",
        "                                        input_shape=P.net_input_dim,\r\n",
        "                                        include_top = False)\r\n",
        "\r\n",
        "    out = resnet.get_layer('conv4_block6_out').output \r\n",
        "\r\n",
        "    out = BottleBlock(output_channels=2048,\r\n",
        "                    dimensions_per_head = 128,\r\n",
        "                    heads = 4,\r\n",
        "                    projection_factor = 4,\r\n",
        "                    downsample = False,\r\n",
        "                    activation = 'relu',\r\n",
        "                    rel_pos_emb = True,\r\n",
        "                    )(out)\r\n",
        "\r\n",
        "    out = BottleBlock(output_channels=2048,\r\n",
        "                    dimensions_per_head = 128,\r\n",
        "                    heads = 4,\r\n",
        "                    projection_factor = 4,\r\n",
        "                    downsample = False,\r\n",
        "                    activation = 'relu',\r\n",
        "                    rel_pos_emb = True,\r\n",
        "                    )(out)\r\n",
        "\r\n",
        "    out = BottleBlock(output_channels=2048,\r\n",
        "                    dimensions_per_head = 128,\r\n",
        "                    heads = 4,\r\n",
        "                    projection_factor = 4,\r\n",
        "                    downsample = False,\r\n",
        "                    activation = 'relu',\r\n",
        "                    rel_pos_emb = True,\r\n",
        "                    )(out)\r\n",
        "\r\n",
        "    out = L.GlobalAvgPool2D()(out)\r\n",
        "    out = L.Dense(P.num_class, activation='softmax')(out)\r\n",
        "\r\n",
        "    model = tf.keras.Model(resnet.input, out)\r\n",
        "    return model "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWElKujel9CD"
      },
      "source": [
        "## LOSS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drh8B8NIjJ0R"
      },
      "source": [
        "def get_loss():\r\n",
        "\r\n",
        "    return tf.keras.losses.SparseCategoricalCrossentropy()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMCQ1HtZmC-K"
      },
      "source": [
        "## OPTIMIZER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAFAAWsomEDa"
      },
      "source": [
        "class CosineDecayWithWarmUP(tf.keras.experimental.CosineDecay):\r\n",
        "    def __init__(self, initial_learning_rate, decay_steps, alpha=0.0, warm_up_step=0, name=None):\r\n",
        "        self.warm_up_step = warm_up_step\r\n",
        "        super(CosineDecayWithWarmUP, self).__init__(initial_learning_rate=initial_learning_rate,\r\n",
        "                                                    decay_steps=decay_steps,\r\n",
        "                                                    alpha=alpha,\r\n",
        "                                                    name=name)\r\n",
        "\r\n",
        "    @tf.function\r\n",
        "    def __call__(self, step):\r\n",
        "        if step <= self.warm_up_step:\r\n",
        "            return step / self.warm_up_step * self.initial_learning_rate\r\n",
        "        else:\r\n",
        "            return super(CosineDecayWithWarmUP, self).__call__(step - self.warm_up_step)\r\n",
        "\r\n",
        "\r\n",
        "def get_optimizer():\r\n",
        "\r\n",
        "    learning_rate_schedules = CosineDecayWithWarmUP(initial_learning_rate= P.initial_learning_rate,\r\n",
        "                                                    decay_steps= P.epoch_num * P.iterations_per_epoch - P.warm_iterations,\r\n",
        "                                                    alpha=P.minimum_learning_rate,\r\n",
        "                                                    warm_up_step=P.warm_iterations)\r\n",
        "    \r\n",
        "    optimizer = optimizers.SGD(learning_rate=learning_rate_schedules, momentum=0.9)\r\n",
        "\r\n",
        "    return optimizer \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCCT3MV2nBW8"
      },
      "source": [
        "## TRAINING DEFINITION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNMcp25NnCeW"
      },
      "source": [
        "def get_model():\r\n",
        "\r\n",
        "    with strategy.scope():\r\n",
        "            \r\n",
        "        if P.architecture == 'resnet':\r\n",
        "            model = build_resnet()\r\n",
        "        elif P.architecture == 'botnet':\r\n",
        "            model = build_bot_trans()\r\n",
        "        else:\r\n",
        "            raise NotImplementedError\r\n",
        "\r\n",
        "        loss = get_loss()\r\n",
        "        opt = get_optimizer()\r\n",
        "\r\n",
        "        metrics = [tf.keras.metrics.SparseCategoricalAccuracy(), \r\n",
        "                tf.keras.metrics.SparseTopKCategoricalAccuracy(k=10)]\r\n",
        "\r\n",
        "        model = model.compile(opt, loss, metrics)\r\n",
        "\r\n",
        "    return model \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjTOpbLUn1F8"
      },
      "source": [
        "# TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2dB0104m4pr"
      },
      "source": [
        "\r\n",
        "\r\n",
        "    \r\n",
        "ds_train, ds_valid = tfds.load(name=\"imagenet2012\", \r\n",
        "                              split=[\"train\", \"validation\"], \r\n",
        "                              data_dir=\"gs://kaggledata2/imgnet\", \r\n",
        "                              builder_kwargs={\"version\": \"5.0.0\"},)\r\n",
        "\r\n",
        "\r\n",
        "ds_train = get_dataset(ds_train, augment=True, repeat=True)\r\n",
        "ds_valid = get_dataset(ds_valid, shuffle=False)\r\n",
        "\r\n",
        "\r\n",
        "model = get_model()\r\n",
        "\r\n",
        "history = model.fit(ds_train,\r\n",
        "            steps_per_epoch  = P.steps_per_epoch,\r\n",
        "            epochs           = P.epochs, \r\n",
        "            validation_data = ds_valid,\r\n",
        "            verbose = 1)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8Fz8c_qpVlv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}